# -*- coding: utf-8 -*-
"""Copy of pix2pix.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fDm7SCF-WppIpoG5G7y5fbLIWHA8l_3l
"""
#Getting the dataset
import cv2 as cv
import torch
import numpy
from google.colab.patches import cv2_imshow
import matplotlib.pyplot as plt
from google.colab import files
files.upload()
#!rm -r ~/.kaggle
!mkdir ~/.kaggle
!mv ./kaggle.json ~/.kaggle/ #When prompted, upload kaggle.json file (pre-downloaded)
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d badasstechie/celebahq-resized-256x256
! unzip celebahq-resized-256x256.zip -d imgs

#Splitting the image folder into test and train subfolders
!pip install split-folders
import splitfolders
splitfolders.ratio('/content/imgs', output="output", seed=42, ratio=(0.3, 0,0.7))

!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix

import os
os.chdir('pytorch-CycleGAN-and-pix2pix/')

!pip install -r requirements.txt

!bash ./scripts/download_pix2pix_model.sh facades_label2photo

#Open CV test 1 on a sample image named "cycle.jpg"
import cv2 as cv
import matplotlib.pyplot as plt
image = cv.imread('/content/cycle.jpg',1)
#image = cv.imread(i,1)
im1 = cv.cvtColor(image,cv.COLOR_BGR2GRAY)
im2 = cv.GaussianBlur(cv.bitwise_not(im1),(21, 21),sigmaX=0, sigmaY=0)
im3 = cv.divide(im1,255-im2,scale=255)
im_3_2 = cv.cvtColor(im3,cv.COLOR_GRAY2BGR)
im4 = cv.hconcat(image[...,::-1],im_3_2)
plt.axis('off')
plt.imshow(im4,cmap="gray")
#plt.savefig(new2)
#plt.imshow(i[...,::-1])

#Open CV test 2 on a sample image named "cycle.jpg"
image = cv.imread('/content/cycle.jpg',1)
#image = cv.imread(i,1)
im0 = cv.cvtColor(image,cv.COLOR_BGR2RGB)
im1 = cv.cvtColor(image,cv.COLOR_BGR2GRAY)
im2 = cv.GaussianBlur(cv.bitwise_not(im1),(21, 21),sigmaX=0, sigmaY=0)
im3 = cv.divide(im1,255-im2,scale=255)
im_3_2 = cv.cvtColor(im3,cv.COLOR_GRAY2BGR)
im4 = cv.hconcat([image[...,::-1],im_3_2])
plt.axis('off')
plt.imshow(im4,cmap="gray")

#Open CV test 3 on a sample image named "cycle.jpg"
image = cv.imread('/content/cycle.jpg',1)
#image = cv.imread(i,1)
im0 = cv.cvtColor(image,cv.COLOR_BGR2RGB)
im1 = cv.cvtColor(im0,cv.COLOR_RGB2GRAY)
im2 = cv.GaussianBlur(cv.bitwise_not(im1),(21, 21),sigmaX=0, sigmaY=0)
im3 = cv.divide(im1,255-im2,scale=255)
im_3_2 = cv.cvtColor(im3,cv.COLOR_GRAY2RGB)
im4 = cv.hconcat([image[...,::-1],im_3_2])
plt.axis('off')
plt.imshow(im4,cmap="gray")
#plt.savefig(new2)

#PIL and OpenCV test 3 on a sample image named "cycle.jpg"
from PIL import Image
import cv2 as cv
import torch
import torchvision
AB = cv.imread('/content/cycle.jpg',1)
A = cv.cvtColor(AB,cv.COLOR_BGR2RGB)
#image=AB.numpy()
im1 = cv.cvtColor(cv.cvtColor(AB,cv.COLOR_BGR2RGB),cv.COLOR_RGB2GRAY)
im2 = cv.GaussianBlur(cv.bitwise_not(im1),(21, 21),sigmaX=0, sigmaY=0)
im3 = cv.divide(im1,255-im2,scale=255)
im_3_2 = cv.cvtColor(im3,cv.COLOR_GRAY2RGB)
im4 = cv.hconcat([A,im_3_2])
#B = torch.from_numpy(im4)
A = Image.fromarray(A)
B = Image.fromarray(im4)

# Commented out IPython magic to ensure Python compatibility. 
# %%writefile /content/pytorch-CycleGAN-and-pix2pix/data/aligned_dataset.py // Uploaded as a separate file in the same folder.
# import os
# from data.base_dataset import BaseDataset, get_params, get_transform
# from data.image_folder import make_dataset
# from PIL import Image
# import cv2 as cv
# import torch
# import torchvision
# 
# class AlignedDataset(BaseDataset):
#     """A dataset class for paired image dataset.
# 
#     It assumes that the directory '/path/to/data/train' contains image pairs in the form of {A,B}.
#     During test time, you need to prepare a directory '/path/to/data/test'.
#     """
# 
#     def __init__(self, opt):
#         """Initialize this dataset class.
# 
#         Parameters:
#             opt (Option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions
#         """
#         BaseDataset.__init__(self, opt)
#         self.dir_AB = os.path.join(opt.dataroot, opt.phase)  # get the image directory
#         self.AB_paths = sorted(make_dataset(self.dir_AB, opt.max_dataset_size))  # get image paths
#         assert(self.opt.load_size >= self.opt.crop_size)   # crop_size should be smaller than the size of loaded image
#         self.input_nc = self.opt.output_nc if self.opt.direction == 'BtoA' else self.opt.input_nc
#         self.output_nc = self.opt.input_nc if self.opt.direction == 'BtoA' else self.opt.output_nc
# 
#     def __getitem__(self, index):
#         """Return a data point and its metadata information.
# 
#         Parameters:
#             index - - a random integer for data indexing
# 
#         Returns a dictionary that contains A, B, A_paths and B_paths
#             A (tensor) - - an image in the input domain
#             B (tensor) - - its corresponding image in the target domain
#             A_paths (str) - - image paths
#             B_paths (str) - - image paths (same as A_paths)
#         """
#         # read a image given a random integer index                         //The modified part of this file.
#         AB_path = self.AB_paths[index]
#         AB = cv.imread(AB_path,1)
#         B = cv.cvtColor(AB,cv.COLOR_BGR2RGB)
#         im1 = cv.cvtColor(cv.cvtColor(AB,cv.COLOR_BGR2RGB),cv.COLOR_RGB2GRAY)
#         im2 = cv.GaussianBlur(cv.bitwise_not(im1),(21, 21),sigmaX=0, sigmaY=0)
#         im3 = cv.divide(im1,255-im2,scale=255)
#         im_3_2 = cv.cvtColor(im3,cv.COLOR_GRAY2RGB)
#         #im4 = cv.hconcat([A,im_3_2])
# 
#         B = Image.fromarray(B)
#         A = Image.fromarray(im_3_2)
# 
#         # apply the same transform to both A and B
#         transform_params = get_params(self.opt, A.size)
#         A_transform = get_transform(self.opt, transform_params, grayscale=(self.input_nc == 1))
#         B_transform = get_transform(self.opt, transform_params, grayscale=(self.output_nc == 1))
# 
#         A = A_transform(A)
#         B = B_transform(B)
# 
#         return {'A': A, 'B': B, 'A_paths': AB_path, 'B_paths': AB_path}
# 
#     def __len__(self):
#         """Return the total number of images in the dataset."""
#         return len(self.AB_paths)
#

!pip install dominate

!python /content/pytorch-CycleGAN-and-pix2pix/train.py --dataroot /content/output  --name facades_pix2pix --model pix2pix --direction AtoB --display_id -1

!pip install visdom
!python -m visdom.server

!python /content/pytorch-CycleGAN-and-pix2pix/test.py --dataroot /content/output  --name facades_pix2pix --model pix2pix --direction AtoB
