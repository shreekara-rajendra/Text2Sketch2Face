# -*- coding: utf-8 -*-
"""Copy of pix2pix.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fDm7SCF-WppIpoG5G7y5fbLIWHA8l_3l
"""
#Getting the dataset
import cv2 as cv
import torch
import numpy
from google.colab.patches import cv2_imshow
import matplotlib.pyplot as plt
from google.colab import files
files.upload()
#!rm -r ~/.kaggle
!mkdir ~/.kaggle
!mv ./kaggle.json ~/.kaggle/     #When prompted, upload kaggle.json file (pre-downloaded)
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d badasstechie/celebahq-resized-256x256
! unzip celebahq-resized-256x256.zip -d imgs

!pip install split-folders
import splitfolders
splitfolders.ratio('/content/imgs', output="output", seed=42, ratio=(0.3, 0,0.7))

!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix

import os
os.chdir('pytorch-CycleGAN-and-pix2pix/')

!pip install -r requirements.txt

!bash ./scripts/download_pix2pix_model.sh facades_label2photo

#test 1 for cv on a localimage named "cycle.jpg"
import cv2 as cv
import matplotlib.pyplot as plt
image = cv.imread('/content/cycle.jpg',1)
#image = cv.imread(i,1)
im1 = cv.cvtColor(image,cv.COLOR_BGR2GRAY)
im2 = cv.GaussianBlur(cv.bitwise_not(im1),(21, 21),sigmaX=0, sigmaY=0)
im3 = cv.divide(im1,255-im2,scale=255)
im_3_2 = cv.cvtColor(im3,cv.COLOR_GRAY2BGR)
im4 = cv.hconcat(image[...,::-1],im_3_2)
plt.axis('off')
plt.imshow(im4,cmap="gray")
#plt.savefig(new2)
#plt.imshow(i[...,::-1])

#test 2 for cv on a localimage named "cycle.jpg"
image = cv.imread('/content/cycle.jpg',1)
#image = cv.imread(i,1)
im0 = cv.cvtColor(image,cv.COLOR_BGR2RGB)
im1 = cv.cvtColor(image,cv.COLOR_BGR2GRAY)
im2 = cv.GaussianBlur(cv.bitwise_not(im1),(21, 21),sigmaX=0, sigmaY=0)
im3 = cv.divide(im1,255-im2,scale=255)
im_3_2 = cv.cvtColor(im3,cv.COLOR_GRAY2BGR)
im4 = cv.hconcat([image[...,::-1],im_3_2])
plt.axis('off')
plt.imshow(im4,cmap="gray")

#test 3 for cv on a localimage named "cycle.jpg"
image = cv.imread('/content/cycle.jpg',1)
#image = cv.imread(i,1)
im0 = cv.cvtColor(image,cv.COLOR_BGR2RGB)
im1 = cv.cvtColor(im0,cv.COLOR_RGB2GRAY)
im2 = cv.GaussianBlur(cv.bitwise_not(im1),(21, 21),sigmaX=0, sigmaY=0)
im3 = cv.divide(im1,255-im2,scale=255)
im_3_2 = cv.cvtColor(im3,cv.COLOR_GRAY2RGB)
im4 = cv.hconcat([image[...,::-1],im_3_2])
plt.axis('off')
plt.imshow(im4,cmap="gray")
#plt.savefig(new2)

#test 4 for cv on a localimage named "cycle.jpg"
from PIL import Image
import cv2 as cv
import torch
import torchvision
AB = cv.imread('/content/cycle.jpg',1)
A = cv.cvtColor(AB,cv.COLOR_BGR2RGB)
#image=AB.numpy()
im1 = cv.cvtColor(cv.cvtColor(AB,cv.COLOR_BGR2RGB),cv.COLOR_RGB2GRAY)
im2 = cv.GaussianBlur(cv.bitwise_not(im1),(21, 21),sigmaX=0, sigmaY=0)
im3 = cv.divide(im1,255-im2,scale=255)
im_3_2 = cv.cvtColor(im3,cv.COLOR_GRAY2RGB)
im4 = cv.hconcat([A,im_3_2])
#B = torch.from_numpy(im4)
A = Image.fromarray(A)
B = Image.fromarray(im4)

!pip install dominate

#training using the modified files of pix2pix
!python /content/pytorch-CycleGAN-and-pix2pix/train.py --dataroot /content/output  --name facades_pix2pix --model pix2pix --direction BtoA --display_id -1

#to check for live status of the model
#!pip install visdom
#!python -m visdom.server

#testing loop
!python /content/pytorch-CycleGAN-and-pix2pix/test.py --dataroot /content/output  --name facades_pix2pix --model pix2pix --direction BtoA
